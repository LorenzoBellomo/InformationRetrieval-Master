{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fdc103d",
   "metadata": {},
   "source": [
    "# Elastic Search\n",
    "Learn to insert documents in a collection, and query those documents in order to retrieve the most relevant ones for your query\n",
    "\n",
    "We first need to install the ElasticSearch library. We need specifically the version 7.14.0 because we will use a server with a working installation of ElasticSearch to do our tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c471695",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install elasticsearch==7.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bddbca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "482ca24d",
   "metadata": {},
   "source": [
    "Now we load the config.json file, because we need a host, port, and credential of the server. Make sure you add your surname in the field config['surname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb941e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file\n",
    "with open(\"../config.json\", 'r') as config_file:\n",
    "    config = json.load(config_file) # load the content of the file in a json object\n",
    "    INDEX_PORT = config['port']\n",
    "    INDEX_HOST = config['host']\n",
    "    INDEX_USER = config['username']\n",
    "    INDEX_PASS = config['psw']\n",
    "    INDEX_NAME = config['surname']\n",
    "    # format HOST and PORT into a full URL for queries\n",
    "    INDEX_URL = 'http://{}:{}/'.format(INDEX_HOST, INDEX_PORT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18885282",
   "metadata": {},
   "source": [
    "Now it is time to create the function to build an elastic search index, deleting any previous one with the same SURNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34ec0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_create():\n",
    "    es = Elasticsearch(INDEX_URL, http_auth=(INDEX_USER, INDEX_PASS))\n",
    "    if es.indices.exists(index=INDEX_NAME):\n",
    "        # this means that an index under your surname is already present\n",
    "        es.indices.delete(index=INDEX_NAME)\n",
    "    es.indices.create(index=INDEX_NAME)\n",
    "    return es"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5165e659",
   "metadata": {},
   "source": [
    "The next function puts three sample documents in the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21dd0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_text_examples(es):\n",
    "    docs = [\"Trump u.s.a. NATO\", \"trump usa N.A.T.O.\", \"the cat sleeps\"]\n",
    "    for line in docs:\n",
    "        document = {'line_content': line.strip()} # strip simply removes leading and trailing whitespaces\n",
    "        es.index(index=INDEX_NAME, body=document) # es.index is the indexing function "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e77a4840",
   "metadata": {},
   "source": [
    "We now created the functions, now we call them to build and populate the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2259dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = index_create()\n",
    "insert_text_examples(es)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2332f6d",
   "metadata": {},
   "source": [
    "We can also see the content from the browser. Just go to the URL [http://kddrtserver15.isti.cnr.it:7777/\\<surname\\>/_search?pretty](http://kddrtserver15.isti.cnr.it:7777/\\<surname\\>/_search?pretty) and put as username and password the same you find on the config.json file.\n",
    "\n",
    "Now let's try some queries. \n",
    "Try some query on our index by providing the input yourself.\n",
    "Queries are modelled with dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a2bb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9808291 - line: trump usa N.A.T.O.\n"
     ]
    }
   ],
   "source": [
    "input_query = input('Insert a query: ').strip()\n",
    "query_body = {'query': {'match': {'line_content': input_query}}}\n",
    "\n",
    "res = es.search(index=INDEX_NAME, body=query_body)\n",
    "for hit in res['hits']['hits']:\n",
    "    print('score: {} - line: {}'.format(hit['_score'], hit['_source']['line_content']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be6740cc",
   "metadata": {},
   "source": [
    "Now let's create a function that makes interesting queries on our index. We will see later how, changing metadata, the results change drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "230ec017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY \"She is sleeping\":\n",
      "================================================================================\n",
      "QUERY \"I am sleeping\":\n",
      "================================================================================\n",
      "QUERY \"I live in the u.s.a.\":\n",
      "score: 0.9808291 - line: Trump u.s.a. NATO\n",
      "score: 0.9808291 - line: the cat sleeps\n",
      "================================================================================\n",
      "QUERY \"TRUMP\":\n",
      "score: 0.4700036 - line: Trump u.s.a. NATO\n",
      "score: 0.4700036 - line: trump usa N.A.T.O.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def example_queries():\n",
    "    queries = [\"She is sleeping\", \"I am sleeping\", \"I live in the u.s.a.\", \"TRUMP\"]\n",
    "    for query in queries:\n",
    "        query_body = {'query': {'match': {'line_content': query.strip()}}}\n",
    "\n",
    "        res = es.search(index=INDEX_NAME, body=query_body)\n",
    "        print(\"QUERY \\\"{}\\\":\".format(query))\n",
    "        for hit in res['hits']['hits']:\n",
    "            print('score: {} - line: {}'.format(hit['_score'], hit['_source']['line_content']))\n",
    "        print(\"================================================================================\")\n",
    "            \n",
    "example_queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef182ec7",
   "metadata": {},
   "source": [
    "## Content Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aec5df3",
   "metadata": {},
   "source": [
    "In this section we will show how to add a text analyzer to the fields, and how it effects queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6906c659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = index_create() # re-create the index\n",
    "mapping =  {\n",
    "    \"properties\": { \n",
    "        \"line_content\": { # field name: we decide this\n",
    "            \"type\": \"text\", # type of the fields of the project\n",
    "            \"analyzer\": \"english\" # this is where we specify the analyzer type\n",
    "        }      \n",
    "    }    \n",
    "}\n",
    "es.indices.put_mapping(index=INDEX_NAME, body=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb77e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_text_examples(es) # we insert again the same previous three elements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90e7ccfe",
   "metadata": {},
   "source": [
    "Try some queries, see how they change with respect to the ones done earlier with no analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa5ce223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9331132 - line: trump usa N.A.T.O.\n"
     ]
    }
   ],
   "source": [
    "input_query = input('Insert a query: ').strip()\n",
    "query_body = {'query': {'match': {'line_content': input_query}}}\n",
    "\n",
    "res = es.search(index=INDEX_NAME, body=query_body)\n",
    "for hit in res['hits']['hits']:\n",
    "    print('score: {} - line: {}'.format(hit['_score'], hit['_source']['line_content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "717cc962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY \"She is sleeping\":\n",
      "score: 1.0925692 - line: the cat sleeps\n",
      "================================================================================\n",
      "QUERY \"I am sleeping\":\n",
      "score: 1.0925692 - line: the cat sleeps\n",
      "================================================================================\n",
      "QUERY \"I live in the u.s.a.\":\n",
      "score: 0.9331132 - line: Trump u.s.a. NATO\n",
      "================================================================================\n",
      "QUERY \"TRUMP\":\n",
      "score: 0.4471386 - line: Trump u.s.a. NATO\n",
      "score: 0.4471386 - line: trump usa N.A.T.O.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "example_queries() # let's run the same queries we did before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac8cd3",
   "metadata": {},
   "source": [
    "## Basic Fields"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61ce3a27",
   "metadata": {},
   "source": [
    "In this section we will show how to add fields to our documents (in this case, the news source of the article)\n",
    "We want two fields, one modelled using the english analyzer, the other one using the white space one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e799b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = index_create() # let's re-create the index\n",
    "mapping = {\n",
    "    \"properties\":{\n",
    "        \"maintext\": { # again, we choose the name of the properties\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"english\" \n",
    "        },\n",
    "        \"source\": { # this would be the news source that wrote the article\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"whitespace\"\n",
    "        }      \n",
    "    }        \n",
    "}\n",
    "es.indices.put_mapping(index=INDEX_NAME, body=mapping)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c700af83",
   "metadata": {},
   "source": [
    "Next we index some articles. 5 articles are provided in the data/texts folder. In the folder is 5 files, each one is a json object with the fields needed for a correct indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce775102",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"../data/texts\" # directory path\n",
    "for filename in os.listdir(dir): # iterate over all the files in the directory\n",
    "    f = os.path.join(dir, filename) # join the directory path with the current filename of the iteration\n",
    "    with open(f, 'r') as article_file: # open the file in read-only mode\n",
    "        text = json.load(article_file) # load the json object containing the article\n",
    "        document = {\"maintext\": text[\"maintext\"], \"source\": text[\"source\"]} # put the fields in the respective keys of a dictionary\n",
    "        es.index(index=INDEX_NAME, body=document) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96e9c1dd",
   "metadata": {},
   "source": [
    "unique sources: \"The New York Times\", \"The Herald-ir\"\n",
    "\n",
    "some words to query for: \"Leclerc\", \"leclerc\", \"the\", \"aircraft\"\n",
    "\n",
    "Try doing some queries as shown here. Pay special care to the \"should\" clause. This means that the article should at least match in some way with one of the clause. But if one of the clauses does not match, this does not create a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aadb737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 results.\n",
      "=====================================================================\n",
      "score: 2.5437517 source: The Herald-ir\n",
      "body: Charles Leclerc\n",
      "Charles Leclerc registered the maiden win of his Formula One career after romp\n"
     ]
    }
   ],
   "source": [
    "source = input(\"Insert a news source: \").strip()\n",
    "terms = input(\"Insert text terms: \").strip()\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [ # at least one of those has to match for the article to be considered\n",
    "                {\"match\": {\"maintext\": terms}}, \n",
    "                {\"match\": {\"source\" : source}}\n",
    "            ]\n",
    "        }      \n",
    "    }        \n",
    "}\n",
    "res = es.search(index=INDEX_NAME, body=query_body)\n",
    "print (\"Found {} results.\".format(res['hits']['total']['value']))\n",
    "for hit in res['hits']['hits']:\n",
    "    print(\"=====================================================================\")\n",
    "    print (\"score: {} source: {}\".format(hit[\"_score\"], hit[\"_source\"][\"source\"]))\n",
    "    print (\"body: {}\".format(hit[\"_source\"][\"maintext\"])[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f5b0b",
   "metadata": {},
   "source": [
    "## Date Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5fed14",
   "metadata": {},
   "source": [
    "In this section we will show how to deal with dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea164d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = index_create()\n",
    "mapping = {\n",
    "    \"properties\":{\n",
    "        \"maintext\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"english\"\n",
    "        },\n",
    "        \"source\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"whitespace\"\n",
    "        },\n",
    "        \"pub-date\": {\n",
    "            \"type\": \"date\",\n",
    "             \"format\": \"yyyy-MM-dd\"\n",
    "        }\n",
    "    }        \n",
    "}\n",
    "es.indices.put_mapping(index=INDEX_NAME, body=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03818ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"../data/texts\"\n",
    "for filename in os.listdir(dir):\n",
    "    f = os.path.join(dir, filename)\n",
    "    with open(f, 'r') as article_file:\n",
    "        text = json.load(article_file)\n",
    "        document = {\"maintext\": text[\"maintext\"], \"source\": text[\"source\"], \"pub-date\": text[\"date\"]}\n",
    "        es.index(index=INDEX_NAME, body=document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb84c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 results.\n",
      "score: 3.5437517 source: The Herald-ir\n",
      "body: Charles Leclerc\n",
      "Charles Leclerc registered the maiden win of his Formula One career after romp\n"
     ]
    }
   ],
   "source": [
    "source = input(\"Insert a news source: \").strip()\n",
    "terms = input(\"Insert text terms: \").strip()\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [{\"match\": {\"maintext\": terms}}, {\"match\": {\"source\": source}}],\n",
    "            \"minimum_should_match\": 1,\n",
    "            \"must\": [{\"range\": {\"pub-date\": {\"lt\":\"2022-01-01\"}}}]\n",
    "        }      \n",
    "    }        \n",
    "}\n",
    "\n",
    "res = es.search(index=INDEX_NAME, body=query_body)\n",
    "print (\"Found {} results.\".format(res['hits']['total']['value']))\n",
    "for hit in res['hits']['hits']:\n",
    "    print (\"score: {} source: {}\".format(hit[\"_score\"], hit[\"_source\"][\"source\"]))\n",
    "    print (\"body: {}\".format(hit[\"_source\"][\"maintext\"])[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b133343",
   "metadata": {},
   "source": [
    "# Boosting Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f39d0d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 results.\n",
      "=====================================================================\n",
      "score: 2.5437517 source: The Herald-ir\n",
      "body: Charles Leclerc\n",
      "Charles Leclerc registered the maiden win of his Formula One career after romp\n",
      "\n",
      "\n",
      "Found 1 results.\n",
      "=====================================================================\n",
      "score: 2.5437517 source: The Herald-ir\n",
      "body: Charles Leclerc\n",
      "Charles Leclerc registered the maiden win of his Formula One career after romp\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source = input(\"Insert a news source: \").strip()\n",
    "terms = input(\"Insert text terms: \").strip()\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                {\"match\": {\"maintext\": terms}}, \n",
    "                {\"match\": {\"source\" : source}}\n",
    "            ]\n",
    "        }      \n",
    "    }        \n",
    "}\n",
    "query_boosted = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                {\n",
    "                    \"match\": {\n",
    "                        \"source\": {\n",
    "                            \"query\": source,\n",
    "                            \"boost\": 3\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"match\": {\n",
    "                        \"maintext\": {\n",
    "                            \"query\": terms,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "for body in [query_body, query_boosted]:\n",
    "    res = es.search(index=INDEX_NAME, body=body)\n",
    "    print (\"Found {} results.\".format(res['hits']['total']['value']))\n",
    "    for hit in res['hits']['hits']:\n",
    "        print(\"=====================================================================\")\n",
    "        print (\"score: {} source: {}\".format(hit[\"_score\"], hit[\"_source\"][\"source\"]))\n",
    "        print (\"body: {}\".format(hit[\"_source\"][\"maintext\"])[:100])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ecb09",
   "metadata": {},
   "source": [
    "# Score description: Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6325281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'bellomo',\n",
       " '_type': '_doc',\n",
       " '_id': 'DdTCcYUBPTSChHKmyjde',\n",
       " 'matched': True,\n",
       " 'explanation': {'value': 2.5437517,\n",
       "  'description': 'sum of:',\n",
       "  'details': [{'value': 2.5437517,\n",
       "    'description': 'weight(maintext:leclerc in 0) [PerFieldSimilarity], result of:',\n",
       "    'details': [{'value': 2.5437517,\n",
       "      'description': 'score(freq=5.0), computed as boost * idf * tf from:',\n",
       "      'details': [{'value': 2.2, 'description': 'boost', 'details': []},\n",
       "       {'value': 1.3862944,\n",
       "        'description': 'idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:',\n",
       "        'details': [{'value': 1,\n",
       "          'description': 'n, number of documents containing term',\n",
       "          'details': []},\n",
       "         {'value': 5,\n",
       "          'description': 'N, total number of documents with field',\n",
       "          'details': []}]},\n",
       "       {'value': 0.83405864,\n",
       "        'description': 'tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:',\n",
       "        'details': [{'value': 5.0,\n",
       "          'description': 'freq, occurrences of term within document',\n",
       "          'details': []},\n",
       "         {'value': 1.2,\n",
       "          'description': 'k1, term saturation parameter',\n",
       "          'details': []},\n",
       "         {'value': 0.75,\n",
       "          'description': 'b, length normalization parameter',\n",
       "          'details': []},\n",
       "         {'value': 216.0,\n",
       "          'description': 'dl, length of field (approximate)',\n",
       "          'details': []},\n",
       "         {'value': 279.8,\n",
       "          'description': 'avgdl, average length of field',\n",
       "          'details': []}]}]}]}]}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = es.explain(id=\"DdTCcYUBPTSChHKmyjde\", index=INDEX_NAME, body=query_boosted)\n",
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "514bff74",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Execute this code to load this set of articles and create an index. It contains 500 articles. \n",
    "The fields are:\n",
    "- *maintext*: Textual content of the article\n",
    "- *source*: News Source that wrote the article\n",
    "- *author*: Person that wrote the article\n",
    "- *date*: the date, in format yyyy-MM-dd\n",
    "\n",
    "UNIQUE SOURCES = [\"La Repubblica\", \"La Stampa\", \"Il Corriere della Sera\", \"Rai News\"]\n",
    "\n",
    "UNIQUE AUTHORS = [\"Paola Candreva\", \"Melchiorre Paccioretti\", \"Caterina De Luca\", \"Marcello Fiorentini\", \"Celestino Necci\"]\n",
    "\n",
    "The date range is 2019-12-05 -> 2020-02-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e51138d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/articles.json\", \"r\") as json_file:\n",
    "    articles = json.load(json_file)\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cabafe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = index_create()\n",
    "mapping = {\n",
    "    \"properties\":{\n",
    "        \"maintext\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"english\"\n",
    "        },\n",
    "        \"source\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"whitespace\"\n",
    "        },\n",
    "        \"pub-date\": {\n",
    "            \"type\": \"date\",\n",
    "             \"format\": \"yyyy-MM-dd\"\n",
    "        },\n",
    "        \"author\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"whitespace\"\n",
    "        },\n",
    "\n",
    "    }        \n",
    "}\n",
    "es.indices.put_mapping(index=INDEX_NAME, body=mapping)\n",
    "for a in articles:\n",
    "    document = {\"maintext\": a[\"maintext\"], \"source\": a[\"source\"], \"pub-date\": a[\"date\"], \"author\": a[\"author\"]}\n",
    "    es.index(index=INDEX_NAME, body=document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ab79d3",
   "metadata": {},
   "source": [
    "# EXERCISE: TRY TO CREATE THIS QUERY\n",
    "Tell me the number of articles that were written by \"Caterina de Luca\" OR published by \"Rai News\", written in the time ranging from the 5th of December 2019 to the 25th of January 2020 (both included), and it contains the word \"world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ccf0e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 results.\n",
      "=====================================================================\n",
      "score: 1.0 source: La Repubblica, author: Celestino Necci\n",
      "body: In fact, some EUR 500 million would be missing from the appeal. Italia Viva continues to deman\n",
      "=====================================================================\n",
      "score: 1.0 source: La Repubblica, author: Celestino Necci\n",
      "body: About a possible alliance with the PD, the Pentastered leader reiterated: “We have a program t\n",
      "=====================================================================\n",
      "score: 1.0 source: Rai News, author: Paola Candreva\n",
      "body: “They were killed in a shooting: they tried to take possession of their guards's weapons but w\n",
      "=====================================================================\n",
      "score: 1.0 source: La Stampa, author: Marcello Fiorentini\n",
      "body: \n",
      "=====================================================================\n",
      "score: 1.0 source: La Repubblica, author: Melchiorre Paccioretti\n",
      "body: The anniversary of the Immaculate Conception\n",
      "=====================================================================\n",
      "score: 1.0 source: La Stampa, author: Paola Candreva\n",
      "body: More than fifty countries that participated in the fifth edition of the International Conferen\n",
      "=====================================================================\n",
      "score: 1.0 source: Il Corriere della Sera, author: Celestino Necci\n",
      "body: Morgan's alarm comes as a result of reports that official government documents leaked online —\n",
      "=====================================================================\n",
      "score: 1.0 source: La Stampa, author: Melchiorre Paccioretti\n",
      "body: He wasn't home. “Targeted because he supports protesters.” Clashes and victims in Baghdad\n",
      "=====================================================================\n",
      "score: 1.0 source: La Repubblica, author: Melchiorre Paccioretti\n",
      "body: Tension is rising in Paris and in other parts of the country where Macron's protest against th\n",
      "=====================================================================\n",
      "score: 1.0 source: La Stampa, author: Marcello Fiorentini\n",
      "body: \n"
     ]
    }
   ],
   "source": [
    "query_body = {} #TODO insert your query here\n",
    "res = es.search(index=INDEX_NAME, body=query_body)\n",
    "print (\"Found {} results.\".format(res['hits']['total']['value']))\n",
    "for hit in res['hits']['hits']:\n",
    "    print(\"=====================================================================\")\n",
    "    print (\"score: {} source: {}, author: {}\".format(hit[\"_score\"], hit[\"_source\"][\"source\"], hit[\"_source\"][\"author\"]))\n",
    "    print (\"body: {}\".format(hit[\"_source\"][\"maintext\"])[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7dcb2",
   "metadata": {},
   "source": [
    "To the brave ones that finished early:\n",
    "**How do I do the exact same query, without the \"world\" clause, but the OR becomes a XOR?** (basically the article is either written by \"Caterina de Luca\" OR published by \"Rai News\", but those two events do not co-exist)\n",
    "So the new query to build is:\n",
    "Tell me the number of articles that were either written by \"Caterina de Luca\" OR published by \"Rai News\", and written in the time ranging from the 5th of December 2019 to the 25th of January 2020 (both included).\n",
    "\n",
    "_HINT_: similarly to \"must\", there is also a \"must_not\" construct.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('IR')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "c226b66ad212a3c8eabd6b6be3829f40d39277fa7bdc3bf63a77768ea80548ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

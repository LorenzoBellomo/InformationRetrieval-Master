{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fdc103d",
   "metadata": {},
   "source": [
    "# Elastic Search\n",
    "Learn to insert documents in a collection, and query those documents in order to retrieve the most relevant ones for your query\n",
    "\n",
    "We first need to install the ElasticSearch library. We need specifically the version 7.14.0 because we will use a server with a working installation of ElasticSearch to do our tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c471695",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install elasticsearch==7.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bddbca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "482ca24d",
   "metadata": {},
   "source": [
    "Now we load the config.json file, because we need a host, port, and credential of the server. Make sure you add your surname in the field config['surname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb941e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file\n",
    "with open(\"config.json\", 'r') as config_file:\n",
    "    config = json.load(config_file) # load the content of the file in a json object\n",
    "    INDEX_PORT = config['port']\n",
    "    INDEX_HOST = config['host']\n",
    "    INDEX_USER = config['username']\n",
    "    INDEX_PASS = config['psw']\n",
    "    INDEX_NAME = config['surname']\n",
    "    # format HOST and PORT into a full URL for queries\n",
    "    INDEX_URL = 'http://{}:{}/'.format(INDEX_HOST, INDEX_PORT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18885282",
   "metadata": {},
   "source": [
    "Now it is time to create the function to build an elastic search index, deleting any previous one with the same SURNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34ec0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_create():\n",
    "    es = Elasticsearch(INDEX_URL, http_auth=(INDEX_USER, INDEX_PASS))\n",
    "    if es.indices.exists(index=INDEX_NAME):\n",
    "        # this means that an index under your surname is already present\n",
    "        es.indices.delete(index=INDEX_NAME)\n",
    "    es.indices.create(index=INDEX_NAME)\n",
    "    return es"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5165e659",
   "metadata": {},
   "source": [
    "The next function puts three sample documents in the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21dd0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_text_examples(es):\n",
    "    docs = [\"Trump u.s.a. NATO\", \"trump usa N.A.T.O.\", \"the cat sleeps\"]\n",
    "    for line in docs:\n",
    "        document = {'line_content': line.strip()} # strip simply removes leading and trailing whitespaces\n",
    "        es.index(index=INDEX_NAME, body=document) # es.index is the indexing function "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e77a4840",
   "metadata": {},
   "source": [
    "We now created the functions, now we call them to build and populate the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2259dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = index_create()\n",
    "insert_text_examples(es)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2332f6d",
   "metadata": {},
   "source": [
    "We can also see the content from the browser. Just go to the URL http://kddrtserver15.isti.cnr.it:7777/\\<surname\\>/_search?pretty and put as username and password the same you find on the config.json file.\n",
    "\n",
    "Now let's try some queries. \n",
    "Try some query on our index by providing the input yourself.\n",
    "Queries are modelled with dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a2bb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.4700036 - line: Trump u.s.a. NATO\n",
      "score: 0.4700036 - line: trump usa N.A.T.O.\n"
     ]
    }
   ],
   "source": [
    "input_query = input('Insert a query: ').strip()\n",
    "query_body = {'query': {'match': {'line_content': input_query}}}\n",
    "\n",
    "res = es.search(index=INDEX_NAME, body=query_body)\n",
    "for hit in res['hits']['hits']:\n",
    "    print('score: {} - line: {}'.format(hit['_score'], hit['_source']['line_content']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be6740cc",
   "metadata": {},
   "source": [
    "Now let's create a function that makes interesting queries on our index. We will see later how, changing metadata, the results change drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "230ec017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY \"She is sleeping\":\n",
      "================================================================================\n",
      "QUERY \"I am sleeping\":\n",
      "================================================================================\n",
      "QUERY \"I live in the u.s.a.\":\n",
      "score: 0.9808291 - line: Trump u.s.a. NATO\n",
      "score: 0.9808291 - line: the cat sleeps\n",
      "================================================================================\n",
      "QUERY \"TRUMP\":\n",
      "score: 0.4700036 - line: Trump u.s.a. NATO\n",
      "score: 0.4700036 - line: trump usa N.A.T.O.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def example_queries():\n",
    "    queries = [\"She is sleeping\", \"I am sleeping\", \"I live in the u.s.a.\", \"TRUMP\"]\n",
    "    for query in queries:\n",
    "        query_body = {'query': {'match': {'line_content': query.strip()}}}\n",
    "\n",
    "        res = es.search(index=INDEX_NAME, body=query_body)\n",
    "        print(\"QUERY \\\"{}\\\":\".format(query))\n",
    "        for hit in res['hits']['hits']:\n",
    "            print('score: {} - line: {}'.format(hit['_score'], hit['_source']['line_content']))\n",
    "        print(\"================================================================================\")\n",
    "            \n",
    "example_queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef182ec7",
   "metadata": {},
   "source": [
    "## Content Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aec5df3",
   "metadata": {},
   "source": [
    "In this section we will show how to add a text analyzer to the fields, and how it effects queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6906c659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = index_create() # re-create the index\n",
    "mapping =  {\n",
    "    \"properties\": { \n",
    "        \"line_content\": { # field name: we decide this\n",
    "            \"type\": \"text\", # type of the fields of the project\n",
    "            \"analyzer\": \"english\" # this is where we specify the analyzer type\n",
    "        }      \n",
    "    }    \n",
    "}\n",
    "es.indices.put_mapping(index=INDEX_NAME, body=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb77e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_text_examples(es) # we insert again the same previous three elements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90e7ccfe",
   "metadata": {},
   "source": [
    "Try some queries, see how they change with respect to the ones done earlier with no analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa5ce223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 1.0925692 - line: the cat sleeps\n"
     ]
    }
   ],
   "source": [
    "input_query = input('Insert a query: ').strip()\n",
    "query_body = {'query': {'match': {'line_content': input_query}}}\n",
    "\n",
    "res = es.search(index=INDEX_NAME, body=query_body)\n",
    "for hit in res['hits']['hits']:\n",
    "    print('score: {} - line: {}'.format(hit['_score'], hit['_source']['line_content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "717cc962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY \"She is sleeping\":\n",
      "score: 1.0925692 - line: the cat sleeps\n",
      "================================================================================\n",
      "QUERY \"I am sleeping\":\n",
      "score: 1.0925692 - line: the cat sleeps\n",
      "================================================================================\n",
      "QUERY \"I live in the u.s.a.\":\n",
      "score: 0.9331132 - line: Trump u.s.a. NATO\n",
      "================================================================================\n",
      "QUERY \"TRUMP\":\n",
      "score: 0.4471386 - line: Trump u.s.a. NATO\n",
      "score: 0.4471386 - line: trump usa N.A.T.O.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "example_queries() # let's run the same queries we did before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac8cd3",
   "metadata": {},
   "source": [
    "## Basic Fields"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61ce3a27",
   "metadata": {},
   "source": [
    "In this section we will show how to add fields to our documents (in this case, the news source of the article)\n",
    "We want two fields, one modelled using the english analyzer, the other one using the white space one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e799b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = index_create() # let's re-create the index\n",
    "mapping = {\n",
    "    \"properties\":{\n",
    "        \"maintext\": { # again, we choose the name of the properties\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"english\" \n",
    "        },\n",
    "        \"source\": { # this would be the news source that wrote the article\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"whitespace\"\n",
    "        }      \n",
    "    }        \n",
    "}\n",
    "es.indices.put_mapping(index=INDEX_NAME, body=mapping)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c700af83",
   "metadata": {},
   "source": [
    "Next we index some articles. 5 articles are provided in the data/texts folder. In the folder is 5 files, each one is a json object with the fields needed for a correct indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce775102",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"data/texts\" # directory path\n",
    "for filename in os.listdir(dir): # iterate over all the files in the directory\n",
    "    f = os.path.join(dir, filename) # join the directory path with the current filename of the iteration\n",
    "    with open(f, 'r') as article_file: # open the file in read-only mode\n",
    "        text = json.load(article_file) # load the json object containing the article\n",
    "        document = {\"maintext\": text[\"maintext\"], \"source\": text[\"source\"]} # put the fields in the respective keys of a dictionary\n",
    "        es.index(index=INDEX_NAME, body=document) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96e9c1dd",
   "metadata": {},
   "source": [
    "unique sources: \"The New York Times\", \"The Herald-ir\"\n",
    "\n",
    "some words to query for: \"Leclerc\", \"leclerc\", \"the\", \"aircraft\"\n",
    "\n",
    "Try doing some queries as shown here. Pay special care to the \"should\" clause. This means that the article should at least match in some way with one of the clause. But if one of the clauses does not match, this does not create a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aadb737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 results.\n",
      "=====================================================================\n",
      "score: 1.331981 source: The Herald-ir\n",
      "body: Luke O'Reilly with his mother Janet O'Brien Luke O'Reilly Jack Hall Ellis The Metro One Bar in\n",
      "=====================================================================\n",
      "score: 1.0892314 source: The New York Times\n",
      "body: The revival of supersonic passenger travel, thought to be long dead with the demise of Concord\n",
      "=====================================================================\n",
      "score: 0.9655346 source: The Herald-ir\n",
      "body: Charles Leclerc\n",
      "Charles Leclerc registered the maiden win of his Formula One career after romp\n"
     ]
    }
   ],
   "source": [
    "source = input(\"Insert a news source: \").strip()\n",
    "terms = input(\"Insert text terms: \").strip()\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [ # at least one of those has to match for the article to be considered\n",
    "                {\"match\": {\"maintext\": terms}}, \n",
    "                {\"match\": {\"source\" : source}}\n",
    "            ]\n",
    "        }      \n",
    "    }        \n",
    "}\n",
    "res = es.search(index=INDEX_NAME, body=query_body)\n",
    "print (\"Found {} results.\".format(res['hits']['total']['value']))\n",
    "for hit in res['hits']['hits']:\n",
    "    print(\"=====================================================================\")\n",
    "    print (\"score: {} source: {}\".format(hit[\"_score\"], hit[\"_source\"][\"source\"]))\n",
    "    print (\"body: {}\".format(hit[\"_source\"][\"maintext\"])[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f5b0b",
   "metadata": {},
   "source": [
    "## Date Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5fed14",
   "metadata": {},
   "source": [
    "In this section we will show how to deal with dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea164d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = index_create()\n",
    "mapping = {\n",
    "    \"properties\":{\n",
    "        \"maintext\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"english\"\n",
    "        },\n",
    "        \"source\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"whitespace\"\n",
    "        },\n",
    "        \"pub-date\": {\n",
    "            \"type\": \"date\",\n",
    "             \"format\": \"yyyy-MM-dd\"\n",
    "        }\n",
    "    }        \n",
    "}\n",
    "es.indices.put_mapping(index=INDEX_NAME, body=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03818ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"texts\"\n",
    "for filename in os.listdir(dir):\n",
    "    f = os.path.join(dir, filename)\n",
    "    with open(f, 'r') as article_file:\n",
    "        text = json.load(article_file)\n",
    "        document = {\"maintext\": text[\"maintext\"], \"source\": text[\"source\"], \"pub-date\": text[\"date\"]}\n",
    "        es.index(index=INDEX_NAME, body=document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb84c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 results.\n",
      "score: 2.425359 source: The Herald-ir\n",
      "body: Luke O'Reilly with his mother Janet O'Brien Luke O'Reilly Jack Hall Ellis The Metro One Bar in\n",
      "score: 2.0589128 source: The Herald-ir\n",
      "body: Charles Leclerc\n",
      "Charles Leclerc registered the maiden win of his Formula One career after romp\n",
      "score: 1.0933781 source: The Herald-ir\n",
      "body: Antonio Conte. Pic: PA\n",
      "Head coach Antonio Conte does not think Chelsea are in the race to sign\n",
      "score: 1.0933781 source: The Herald-ir\n",
      "body: Hamid Sanambar\n",
      "Gardai are hunting for a gunman who opened fire on a car in north Dublin - just\n"
     ]
    }
   ],
   "source": [
    "source = input(\"Insert a news source: \").strip()\n",
    "terms = input(\"Insert text terms: \").strip()\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [{\"match\": {\"maintext\": terms}}, {\"match\": {\"source\": source}}],\n",
    "            \"minimum_should_match\": 1,\n",
    "            \"must\": [{\"range\": {\"pub-date\": {\"lt\":\"2022-01-01\"}}}]\n",
    "        }      \n",
    "    }        \n",
    "}\n",
    "\n",
    "res = es.search(index=INDEX_NAME, body=query_body)\n",
    "print (\"Found {} results.\".format(res['hits']['total']['value']))\n",
    "for hit in res['hits']['hits']:\n",
    "    print (\"score: {} source: {}\".format(hit[\"_score\"], hit[\"_source\"][\"source\"]))\n",
    "    print (\"body: {}\".format(hit[\"_source\"][\"maintext\"])[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b133343",
   "metadata": {},
   "source": [
    "# Boosting Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f39d0d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 results.\n",
      "=====================================================================\n",
      "score: 3.3360603 source: The New York Times\n",
      "body: The revival of supersonic passenger travel, thought to be long dead with the demise of Concord\n",
      "=====================================================================\n",
      "score: 1.425359 source: The Herald-ir\n",
      "body: Luke O'Reilly with his mother Janet O'Brien Luke O'Reilly Jack Hall Ellis The Metro One Bar in\n",
      "=====================================================================\n",
      "score: 1.0589126 source: The Herald-ir\n",
      "body: Charles Leclerc\n",
      "Charles Leclerc registered the maiden win of his Formula One career after romp\n",
      "=====================================================================\n",
      "score: 0.09337806 source: The Herald-ir\n",
      "body: Antonio Conte. Pic: PA\n",
      "Head coach Antonio Conte does not think Chelsea are in the race to sign\n",
      "=====================================================================\n",
      "score: 0.09337806 source: The Herald-ir\n",
      "body: Hamid Sanambar\n",
      "Gardai are hunting for a gunman who opened fire on a car in north Dublin - just\n",
      "\n",
      "\n",
      "Found 5 results.\n",
      "=====================================================================\n",
      "score: 10.008182 source: The New York Times\n",
      "body: The revival of supersonic passenger travel, thought to be long dead with the demise of Concord\n",
      "=====================================================================\n",
      "score: 1.6121151 source: The Herald-ir\n",
      "body: Luke O'Reilly with his mother Janet O'Brien Luke O'Reilly Jack Hall Ellis The Metro One Bar in\n",
      "=====================================================================\n",
      "score: 1.2456688 source: The Herald-ir\n",
      "body: Charles Leclerc\n",
      "Charles Leclerc registered the maiden win of his Formula One career after romp\n",
      "=====================================================================\n",
      "score: 0.28013417 source: The Herald-ir\n",
      "body: Antonio Conte. Pic: PA\n",
      "Head coach Antonio Conte does not think Chelsea are in the race to sign\n",
      "=====================================================================\n",
      "score: 0.28013417 source: The Herald-ir\n",
      "body: Hamid Sanambar\n",
      "Gardai are hunting for a gunman who opened fire on a car in north Dublin - just\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source = input(\"Insert a news source: \").strip()\n",
    "terms = input(\"Insert text terms: \").strip()\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                {\"match\": {\"maintext\": terms}}, \n",
    "                {\"match\": {\"source\" : source}}\n",
    "            ]\n",
    "        }      \n",
    "    }        \n",
    "}\n",
    "query_boosted = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                {\n",
    "                    \"match\": {\n",
    "                        \"source\": {\n",
    "                            \"query\": source,\n",
    "                            \"boost\": 3\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"match\": {\n",
    "                        \"maintext\": {\n",
    "                            \"query\": terms,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "for body in [query_body, query_boosted]:\n",
    "    res = es.search(index=INDEX_NAME, body=body)\n",
    "    print (\"Found {} results.\".format(res['hits']['total']['value']))\n",
    "    for hit in res['hits']['hits']:\n",
    "        print(\"=====================================================================\")\n",
    "        print (\"score: {} source: {}\".format(hit[\"_score\"], hit[\"_source\"][\"source\"]))\n",
    "        print (\"body: {}\".format(hit[\"_source\"][\"maintext\"])[:100])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ecb09",
   "metadata": {},
   "source": [
    "# Score description: Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6325281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'bellomo',\n",
       " '_type': '_doc',\n",
       " '_id': 'kNRlr4QBPTSChHKmOhMc',\n",
       " 'matched': True,\n",
       " 'explanation': {'value': 10.008182,\n",
       "  'description': 'sum of:',\n",
       "  'details': [{'value': 10.008182,\n",
       "    'description': 'sum of:',\n",
       "    'details': [{'value': 0.20509824,\n",
       "      'description': 'weight(source:The in 0) [PerFieldSimilarity], result of:',\n",
       "      'details': [{'value': 0.20509824,\n",
       "        'description': 'score(freq=1.0), computed as boost * idf * tf from:',\n",
       "        'details': [{'value': 6.6000004,\n",
       "          'description': 'boost',\n",
       "          'details': []},\n",
       "         {'value': 0.087011375,\n",
       "          'description': 'idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:',\n",
       "          'details': [{'value': 5,\n",
       "            'description': 'n, number of documents containing term',\n",
       "            'details': []},\n",
       "           {'value': 5,\n",
       "            'description': 'N, total number of documents with field',\n",
       "            'details': []}]},\n",
       "         {'value': 0.35714287,\n",
       "          'description': 'tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:',\n",
       "          'details': [{'value': 1.0,\n",
       "            'description': 'freq, occurrences of term within document',\n",
       "            'details': []},\n",
       "           {'value': 1.2,\n",
       "            'description': 'k1, term saturation parameter',\n",
       "            'details': []},\n",
       "           {'value': 0.75,\n",
       "            'description': 'b, length normalization parameter',\n",
       "            'details': []},\n",
       "           {'value': 4.0, 'description': 'dl, length of field', 'details': []},\n",
       "           {'value': 2.4,\n",
       "            'description': 'avgdl, average length of field',\n",
       "            'details': []}]}]}]},\n",
       "     {'value': 3.2676945,\n",
       "      'description': 'weight(source:New in 0) [PerFieldSimilarity], result of:',\n",
       "      'details': [{'value': 3.2676945,\n",
       "        'description': 'score(freq=1.0), computed as boost * idf * tf from:',\n",
       "        'details': [{'value': 6.6000004,\n",
       "          'description': 'boost',\n",
       "          'details': []},\n",
       "         {'value': 1.3862944,\n",
       "          'description': 'idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:',\n",
       "          'details': [{'value': 1,\n",
       "            'description': 'n, number of documents containing term',\n",
       "            'details': []},\n",
       "           {'value': 5,\n",
       "            'description': 'N, total number of documents with field',\n",
       "            'details': []}]},\n",
       "         {'value': 0.35714287,\n",
       "          'description': 'tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:',\n",
       "          'details': [{'value': 1.0,\n",
       "            'description': 'freq, occurrences of term within document',\n",
       "            'details': []},\n",
       "           {'value': 1.2,\n",
       "            'description': 'k1, term saturation parameter',\n",
       "            'details': []},\n",
       "           {'value': 0.75,\n",
       "            'description': 'b, length normalization parameter',\n",
       "            'details': []},\n",
       "           {'value': 4.0, 'description': 'dl, length of field', 'details': []},\n",
       "           {'value': 2.4,\n",
       "            'description': 'avgdl, average length of field',\n",
       "            'details': []}]}]}]},\n",
       "     {'value': 3.2676945,\n",
       "      'description': 'weight(source:York in 0) [PerFieldSimilarity], result of:',\n",
       "      'details': [{'value': 3.2676945,\n",
       "        'description': 'score(freq=1.0), computed as boost * idf * tf from:',\n",
       "        'details': [{'value': 6.6000004,\n",
       "          'description': 'boost',\n",
       "          'details': []},\n",
       "         {'value': 1.3862944,\n",
       "          'description': 'idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:',\n",
       "          'details': [{'value': 1,\n",
       "            'description': 'n, number of documents containing term',\n",
       "            'details': []},\n",
       "           {'value': 5,\n",
       "            'description': 'N, total number of documents with field',\n",
       "            'details': []}]},\n",
       "         {'value': 0.35714287,\n",
       "          'description': 'tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:',\n",
       "          'details': [{'value': 1.0,\n",
       "            'description': 'freq, occurrences of term within document',\n",
       "            'details': []},\n",
       "           {'value': 1.2,\n",
       "            'description': 'k1, term saturation parameter',\n",
       "            'details': []},\n",
       "           {'value': 0.75,\n",
       "            'description': 'b, length normalization parameter',\n",
       "            'details': []},\n",
       "           {'value': 4.0, 'description': 'dl, length of field', 'details': []},\n",
       "           {'value': 2.4,\n",
       "            'description': 'avgdl, average length of field',\n",
       "            'details': []}]}]}]},\n",
       "     {'value': 3.2676945,\n",
       "      'description': 'weight(source:Times in 0) [PerFieldSimilarity], result of:',\n",
       "      'details': [{'value': 3.2676945,\n",
       "        'description': 'score(freq=1.0), computed as boost * idf * tf from:',\n",
       "        'details': [{'value': 6.6000004,\n",
       "          'description': 'boost',\n",
       "          'details': []},\n",
       "         {'value': 1.3862944,\n",
       "          'description': 'idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:',\n",
       "          'details': [{'value': 1,\n",
       "            'description': 'n, number of documents containing term',\n",
       "            'details': []},\n",
       "           {'value': 5,\n",
       "            'description': 'N, total number of documents with field',\n",
       "            'details': []}]},\n",
       "         {'value': 0.35714287,\n",
       "          'description': 'tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:',\n",
       "          'details': [{'value': 1.0,\n",
       "            'description': 'freq, occurrences of term within document',\n",
       "            'details': []},\n",
       "           {'value': 1.2,\n",
       "            'description': 'k1, term saturation parameter',\n",
       "            'details': []},\n",
       "           {'value': 0.75,\n",
       "            'description': 'b, length normalization parameter',\n",
       "            'details': []},\n",
       "           {'value': 4.0, 'description': 'dl, length of field', 'details': []},\n",
       "           {'value': 2.4,\n",
       "            'description': 'avgdl, average length of field',\n",
       "            'details': []}]}]}]}]}]}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = es.explain(id=\"kNRlr4QBPTSChHKmOhMc\", index=INDEX_NAME, body=query_boosted)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514bff74",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Execute this code to load this set of articles and create an index. It contains 1429 articles. \n",
    "The fields are:\n",
    "- *maintext*: Textual content of the article\n",
    "- *source*: News Source that wrote the article\n",
    "- *author*: Person that wrote the article\n",
    "- *date*: the date, in format yyyy-MM-dd\n",
    "\n",
    "UNIQUE SOURCES = [\"La Repubblica\", \"La Stampa\", \"Il Corriere della Sera\", \"Rai News\"]\n",
    "\n",
    "UNIQUE AUTHORS = [\"Paola Candreva\", \"Melchiorre Paccioretti\", \"Caterina De Luca\", \"Marcello Fiorentini\", \"Celestino Necci\"]\n",
    "\n",
    "The date range is 2019-12-05 -> 2020-02-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e51138d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"articles.json\", \"r\") as json_file:\n",
    "    articles = json.load(json_file)\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cabafe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = index_create()\n",
    "mapping = {\n",
    "    \"properties\":{\n",
    "        \"maintext\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"english\"\n",
    "        },\n",
    "        \"source\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"whitespace\"\n",
    "        },\n",
    "        \"pub-date\": {\n",
    "            \"type\": \"date\",\n",
    "             \"format\": \"yyyy-MM-dd\"\n",
    "        },\n",
    "        \"author\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"whitespace\"\n",
    "        },\n",
    "\n",
    "    }        \n",
    "}\n",
    "es.indices.put_mapping(index=INDEX_NAME, body=mapping)\n",
    "for a in articles:\n",
    "    document = {\"maintext\": a[\"maintext\"], \"source\": a[\"source\"], \"pub-date\": a[\"date\"], \"author\": a[\"author\"]}\n",
    "    es.index(index=INDEX_NAME, body=document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ab79d3",
   "metadata": {},
   "source": [
    "# EXERCISE: TRY TO CREATE THIS QUERY\n",
    "Tell me the number of articles that were written by \"Caterina de Luca\" OR published by \"Rai News\", written in the time ranging from the 5th of December 2019 to the 25th of January 2020 (both included), and it contains the word \"world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ccf0e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 results.\n",
      "=====================================================================\n",
      "score: 1.0 source: Il Corriere della Sera, author: Melchiorre Paccioretti\n",
      "body: After the controversy the executive corrects the norm on plastic. Medical devices and single-u\n",
      "=====================================================================\n",
      "score: 1.0 source: Rai News, author: Celestino Necci\n",
      "body: Trump attacks Trudeau: “Hypocrite, he has a double face.” Then cancel the press conference. “I\n",
      "=====================================================================\n",
      "score: 1.0 source: Rai News, author: Caterina De Luca\n",
      "body: The images arrive three months after the US President's visit to Otay Mesa Immigrant Detention\n",
      "=====================================================================\n",
      "score: 1.0 source: La Repubblica, author: Paola Candreva\n",
      "body: Zelimkhan Khangoshvili, former Chechen rebel commander, was murdered on 23 August in a park in\n",
      "=====================================================================\n",
      "score: 1.0 source: Rai News, author: Marcello Fiorentini\n",
      "body: Victims are civilians: the attacker took his own life\n",
      "=====================================================================\n",
      "score: 1.0 source: La Repubblica, author: Melchiorre Paccioretti\n",
      "body: The traditional party for lighting up the lights\n",
      "=====================================================================\n",
      "score: 1.0 source: La Stampa, author: Celestino Necci\n",
      "body: 250 events are planned throughout the country, one of the most impressive of recent years. The\n",
      "=====================================================================\n",
      "score: 1.0 source: Rai News, author: Caterina De Luca\n",
      "body: Paris is preparing for a weekend of heavy inconvenience on the metro and bus. The trade unions\n",
      "=====================================================================\n",
      "score: 1.0 source: La Stampa, author: Celestino Necci\n",
      "body: The Pontiff takes the cue from the crib to talk about the preservation of the environment and \n",
      "=====================================================================\n",
      "score: 1.0 source: Rai News, author: Paola Candreva\n",
      "body: A majority system is therefore definitively excluded, including the double shift initially pro\n"
     ]
    }
   ],
   "source": [
    "query_body = {} #TODO insert your query here\n",
    "res = es.search(index=INDEX_NAME, body=query_body)\n",
    "print (\"Found {} results.\".format(res['hits']['total']['value']))\n",
    "for hit in res['hits']['hits']:\n",
    "    print(\"=====================================================================\")\n",
    "    print (\"score: {} source: {}, author: {}\".format(hit[\"_score\"], hit[\"_source\"][\"source\"], hit[\"_source\"][\"author\"]))\n",
    "    print (\"body: {}\".format(hit[\"_source\"][\"maintext\"])[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7dcb2",
   "metadata": {},
   "source": [
    "To the brave ones that finished early:\n",
    "**How do I do the exact same query, without the \"world\" clause, but the OR becomes a XOR?** (basically the article is either written by \"Caterina de Luca\" OR published by \"Rai News\", but those two events do not co-exist)\n",
    "So the new query to build is:\n",
    "Tell me the number of articles that were either written by \"Caterina de Luca\" OR published by \"Rai News\", and written in the time ranging from the 5th of December 2019 to the 25th of January 2020 (both included).\n",
    "\n",
    "_HINT_: similarly to \"must\", there is also a \"must_not\" construct.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('IR')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "c226b66ad212a3c8eabd6b6be3829f40d39277fa7bdc3bf63a77768ea80548ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

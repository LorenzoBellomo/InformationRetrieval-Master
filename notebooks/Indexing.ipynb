{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fdc103d",
   "metadata": {},
   "source": [
    "# Elastic Search\n",
    "Learn to insert documents in a collection, and query those documents in order to retrieve the most relevant ones for your query\n",
    "\n",
    "We first need to install the ElasticSearch library. We need specifically the version 7.14.0 because we will use a server with a working installation of ElasticSearch to do our tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c471695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch==7.14.0 in c:\\users\\loren\\anaconda3\\envs\\ir\\lib\\site-packages (7.14.0)\n",
      "Requirement already satisfied: urllib3<2,>=1.21.1 in c:\\users\\loren\\anaconda3\\envs\\ir\\lib\\site-packages (from elasticsearch==7.14.0) (1.26.16)\n",
      "Requirement already satisfied: certifi in c:\\users\\loren\\anaconda3\\envs\\ir\\lib\\site-packages (from elasticsearch==7.14.0) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install elasticsearch==7.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bddbca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ca24d",
   "metadata": {},
   "source": [
    "Now we load the config.json file, because we need a host, port, and credential of the server. Make sure you add your surname in the field config['surname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb941e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file\n",
    "with open(\"../config.json\", 'r') as config_file:\n",
    "    config = json.load(config_file) # load the content of the file in a json object\n",
    "    INDEX_PORT = config['port']\n",
    "    INDEX_HOST = config['host']\n",
    "    INDEX_USER = config['username']\n",
    "    INDEX_PASS = config['psw']\n",
    "    INDEX_NAME = config['surname']\n",
    "    # format HOST and PORT into a full URL for queries\n",
    "    INDEX_URL = 'http://{}:{}/'.format(INDEX_HOST, INDEX_PORT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18885282",
   "metadata": {},
   "source": [
    "Now it is time to create the function to build an elastic search index, deleting any previous one with the same SURNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34ec0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_create():\n",
    "    es = Elasticsearch(INDEX_URL, http_auth=(INDEX_USER, INDEX_PASS))\n",
    "    if es.indices.exists(index=INDEX_NAME):\n",
    "        # this means that an index under your surname is already present\n",
    "        es.indices.delete(index=INDEX_NAME)\n",
    "    es.indices.create(index=INDEX_NAME)\n",
    "    return es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5165e659",
   "metadata": {},
   "source": [
    "The next function puts three sample documents in the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21dd0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_text_examples(es):\n",
    "    docs = [\"Trump u.s.a. NATO\", \"trump usa N.A.T.O.\", \"the cat sleeps\"]\n",
    "    for line in docs:\n",
    "        document = {'line_content': line.strip()} # strip simply removes leading and trailing whitespaces\n",
    "        es.index(index=INDEX_NAME, body=document) # es.index is the indexing function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77a4840",
   "metadata": {},
   "source": [
    "We now created the functions, now we call them to build and populate the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2259dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = index_create()\n",
    "insert_text_examples(es)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2332f6d",
   "metadata": {},
   "source": [
    "We can also see the content from the browser. Just go to the URL [http://kddrtserver15.isti.cnr.it:7777/\\<surname\\>/_search?pretty](http://kddrtserver15.isti.cnr.it:7777/\\<surname\\>/_search?pretty) and put as username and password the same you find on the config.json file.\n",
    "\n",
    "Now let's try some queries. \n",
    "Try some query on our index by providing the input yourself.\n",
    "Queries are modelled with dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a2bb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert a query: trump\n",
      "score: 0.4700036 - line: Trump u.s.a. NATO\n",
      "score: 0.4700036 - line: trump usa N.A.T.O.\n"
     ]
    }
   ],
   "source": [
    "input_query = input('Insert a query: ').strip()\n",
    "query_body = {'query': {'match': {'line_content': input_query}}}\n",
    "\n",
    "res = es.search(index=INDEX_NAME, body=query_body)\n",
    "for hit in res['hits']['hits']:\n",
    "    print('score: {} - line: {}'.format(hit['_score'], hit['_source']['line_content']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6740cc",
   "metadata": {},
   "source": [
    "Now let's create a function that makes interesting queries on our index. We will see later how, changing metadata, the results change drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "230ec017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY \"She is sleeping\":\n",
      "================================================================================\n",
      "QUERY \"I am sleeping\":\n",
      "================================================================================\n",
      "QUERY \"I live in the u.s.a.\":\n",
      "score: 0.9808291 - line: Trump u.s.a. NATO\n",
      "score: 0.9808291 - line: the cat sleeps\n",
      "================================================================================\n",
      "QUERY \"TRUMP\":\n",
      "score: 0.4700036 - line: Trump u.s.a. NATO\n",
      "score: 0.4700036 - line: trump usa N.A.T.O.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def example_queries():\n",
    "    queries = [\"She is sleeping\", \"I am sleeping\", \"I live in the u.s.a.\", \"TRUMP\"]\n",
    "    for query in queries:\n",
    "        query_body = {'query': {'match': {'line_content': query.strip()}}}\n",
    "\n",
    "        res = es.search(index=INDEX_NAME, body=query_body)\n",
    "        print(\"QUERY \\\"{}\\\":\".format(query))\n",
    "        for hit in res['hits']['hits']:\n",
    "            print('score: {} - line: {}'.format(hit['_score'], hit['_source']['line_content']))\n",
    "        print(\"================================================================================\")\n",
    "            \n",
    "example_queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef182ec7",
   "metadata": {},
   "source": [
    "## Content Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aec5df3",
   "metadata": {},
   "source": [
    "In this section we will show how to add a text analyzer to the fields, and how it effects queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6906c659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = index_create() # re-create the index\n",
    "mapping =  {\n",
    "    \"properties\": { \n",
    "        \"line_content\": { # field name: we decide this\n",
    "            \"type\": \"text\", # type of the fields of the project\n",
    "            \"analyzer\": \"english\" # this is where we specify the analyzer type\n",
    "        }      \n",
    "    }    \n",
    "}\n",
    "es.indices.put_mapping(index=INDEX_NAME, body=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb77e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_text_examples(es) # we insert again the same previous three elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e7ccfe",
   "metadata": {},
   "source": [
    "Try some queries, see how they change with respect to the ones done earlier with no analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa5ce223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert a query: trump\n",
      "score: 0.4471386 - line: Trump u.s.a. NATO\n",
      "score: 0.4471386 - line: trump usa N.A.T.O.\n"
     ]
    }
   ],
   "source": [
    "input_query = input('Insert a query: ').strip()\n",
    "query_body = {'query': {'match': {'line_content': input_query}}}\n",
    "\n",
    "res = es.search(index=INDEX_NAME, body=query_body)\n",
    "for hit in res['hits']['hits']:\n",
    "    print('score: {} - line: {}'.format(hit['_score'], hit['_source']['line_content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "717cc962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY \"She is sleeping\":\n",
      "score: 1.0925692 - line: the cat sleeps\n",
      "================================================================================\n",
      "QUERY \"I am sleeping\":\n",
      "score: 1.0925692 - line: the cat sleeps\n",
      "================================================================================\n",
      "QUERY \"I live in the u.s.a.\":\n",
      "score: 0.9331132 - line: Trump u.s.a. NATO\n",
      "================================================================================\n",
      "QUERY \"TRUMP\":\n",
      "score: 0.4471386 - line: Trump u.s.a. NATO\n",
      "score: 0.4471386 - line: trump usa N.A.T.O.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "example_queries() # let's run the same queries we did before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac8cd3",
   "metadata": {},
   "source": [
    "## Basic Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce3a27",
   "metadata": {},
   "source": [
    "In this section we will show how to add fields to our documents (in this case, the news source of the article)\n",
    "We want two fields, one modelled using the english analyzer, the other one using the white space one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e799b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = index_create() # let's re-create the index\n",
    "mapping = {\n",
    "    \"properties\":{\n",
    "        \"maintext\": { # again, we choose the name of the properties\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"english\" \n",
    "        },\n",
    "        \"source\": { # this would be the news source that wrote the article\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"whitespace\"\n",
    "        }      \n",
    "    }        \n",
    "}\n",
    "es.indices.put_mapping(index=INDEX_NAME, body=mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c700af83",
   "metadata": {},
   "source": [
    "Next we index some articles. 5 articles are provided in the data/texts folder. In the folder is 5 files, each one is a json object with the fields needed for a correct indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce775102",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"../data/texts\" # directory path\n",
    "for filename in os.listdir(dir): # iterate over all the files in the directory\n",
    "    f = os.path.join(dir, filename) # join the directory path with the current filename of the iteration\n",
    "    with open(f, 'r') as article_file: # open the file in read-only mode\n",
    "        text = json.load(article_file) # load the json object containing the article\n",
    "        document = {\"maintext\": text[\"maintext\"], \"source\": text[\"source\"]} # put the fields in the respective keys of a dictionary\n",
    "        es.index(index=INDEX_NAME, body=document) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e9c1dd",
   "metadata": {},
   "source": [
    "unique sources: \"The New York Times\", \"The Herald-ir\"\n",
    "\n",
    "some words to query for: \"Leclerc\", \"leclerc\", \"the\", \"aircraft\"\n",
    "\n",
    "Try doing some queries as shown here. Pay special care to the \"should\" clause. This means that the article should at least match in some way with one of the clause. But if one of the clauses does not match, this does not create a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aadb737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert a news source: Times\n",
      "Insert text terms: leclerc\n",
      "Found 2 results.\n",
      "=====================================================================\n",
      "score: 2.5437517 source: The Herald-ir\n",
      "body: Charles Leclerc\n",
      "Charles Leclerc registered the maiden win of his Formula One career after romp\n",
      "=====================================================================\n",
      "score: 1.0892314 source: The New York Times\n",
      "body: The revival of supersonic passenger travel, thought to be long dead with the demise of Concord\n"
     ]
    }
   ],
   "source": [
    "source = input(\"Insert a news source: \").strip()\n",
    "terms = input(\"Insert text terms: \").strip()\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [ # at least one of those has to match for the article to be considered\n",
    "                {\"match\": {\"maintext\": terms}}, \n",
    "                {\"match\": {\"source\" : source}}\n",
    "            ]\n",
    "        }      \n",
    "    }        \n",
    "}\n",
    "res = es.search(index=INDEX_NAME, body=query_body)\n",
    "print (\"Found {} results.\".format(res['hits']['total']['value']))\n",
    "for hit in res['hits']['hits']:\n",
    "    print(\"=====================================================================\")\n",
    "    print (\"score: {} source: {}\".format(hit[\"_score\"], hit[\"_source\"][\"source\"]))\n",
    "    print (\"body: {}\".format(hit[\"_source\"][\"maintext\"])[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f5b0b",
   "metadata": {},
   "source": [
    "## Date Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5fed14",
   "metadata": {},
   "source": [
    "In this section we will show how to deal with dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea164d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = index_create()\n",
    "mapping = {\n",
    "    \"properties\":{\n",
    "        \"maintext\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"english\"\n",
    "        },\n",
    "        \"source\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"whitespace\"\n",
    "        },\n",
    "        \"pub-date\": {\n",
    "            \"type\": \"date\",\n",
    "             \"format\": \"yyyy-MM-dd\"\n",
    "        }\n",
    "    }        \n",
    "}\n",
    "es.indices.put_mapping(index=INDEX_NAME, body=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03818ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"../data/texts\"\n",
    "for filename in os.listdir(dir):\n",
    "    f = os.path.join(dir, filename)\n",
    "    with open(f, 'r') as article_file:\n",
    "        text = json.load(article_file)\n",
    "        document = {\"maintext\": text[\"maintext\"], \"source\": text[\"source\"], \"pub-date\": text[\"date\"]}\n",
    "        es.index(index=INDEX_NAME, body=document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb84c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert a news source: Times\n",
      "Insert text terms: leclerc\n",
      "Found 1 results.\n",
      "score: 3.5437517 source: The Herald-ir\n",
      "body: Charles Leclerc\n",
      "Charles Leclerc registered the maiden win of his Formula One career after romp\n"
     ]
    }
   ],
   "source": [
    "source = input(\"Insert a news source: \").strip()\n",
    "terms = input(\"Insert text terms: \").strip()\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [{\"match\": {\"maintext\": terms}}, {\"match\": {\"source\": source}}],\n",
    "            \"minimum_should_match\": 1,\n",
    "            \"must\": [{\"range\": {\"pub-date\": {\"lt\":\"2022-01-01\"}}}]\n",
    "        }      \n",
    "    }        \n",
    "}\n",
    "\n",
    "res = es.search(index=INDEX_NAME, body=query_body)\n",
    "print (\"Found {} results.\".format(res['hits']['total']['value']))\n",
    "for hit in res['hits']['hits']:\n",
    "    print (\"score: {} source: {}\".format(hit[\"_score\"], hit[\"_source\"][\"source\"]))\n",
    "    print (\"body: {}\".format(hit[\"_source\"][\"maintext\"])[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66f3bd6",
   "metadata": {},
   "source": [
    "Query: Given source s and text t, find all news that match either s in \"source\" OR t in \"maintext\", AND have publication date which is either smaller than 01/01/2019 OR larger than 01/01/2022. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "492bbcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert a news source: The\n",
      "Insert text terms: \n",
      "Found 2 results.\n",
      "\n",
      "\n",
      "score: 1.0933781 source: The Herald-ir\n",
      "body: Antonio Conte. Pic: PA\n",
      "Head coach Antonio Conte does not think Chelsea are in the race to sign\n",
      "Publication date is: 2018-01-23\n",
      "\n",
      "\n",
      "score: 1.068366 source: The New York Times\n",
      "body: The revival of supersonic passenger travel, thought to be long dead with the demise of Concord\n",
      "Publication date is: 2022-08-18\n"
     ]
    }
   ],
   "source": [
    "source = input(\"Insert a news source: \").strip()\n",
    "terms = input(\"Insert text terms: \").strip()\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [ #AND\n",
    "                {\n",
    "                    \"bool\": {\n",
    "                        \"should\": [ # FIRST OR\n",
    "                            {\"match\": {\"source\": source}},\n",
    "                            {\"match\": {\"maintext\": terms}},\n",
    "                        ],\n",
    "                        \"minimum_should_match\": 1\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"bool\": {\n",
    "                        \"should\": [ # SECOND OR\n",
    "                            {\"range\": {\"pub-date\": {'gt': \"2022-01-01\"}}},\n",
    "                            {\"range\": {\"pub-date\": {'lt': \"2019-01-01\"}}}\n",
    "                        ],\n",
    "                        \"minimum_should_match\": 1\n",
    "                    }\n",
    "                } \n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "res = es.search(index=INDEX_NAME, body=query_body)\n",
    "print (\"Found {} results.\".format(res['hits']['total']['value']))\n",
    "for hit in res['hits']['hits']:\n",
    "    print(\"\\n\")\n",
    "    print (\"score: {} source: {}\".format(hit[\"_score\"], hit[\"_source\"][\"source\"]))\n",
    "    print (\"body: {}\".format(hit[\"_source\"][\"maintext\"])[:100])\n",
    "    print (\"Publication date is: {}\".format(hit[\"_source\"][\"pub-date\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b133343",
   "metadata": {},
   "source": [
    "# Boosting Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f39d0d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert a news source: Times \n",
      "Insert text terms: leclerc\n",
      "Found 2 results.\n",
      "=====================================================================\n",
      "score: 2.5437517 source: The Herald-ir\n",
      "body: Charles Leclerc\n",
      "Charles Leclerc registered the maiden win of his Formula One career after romp\n",
      "=====================================================================\n",
      "score: 1.0892314 source: The New York Times\n",
      "body: The revival of supersonic passenger travel, thought to be long dead with the demise of Concord\n",
      "\n",
      "\n",
      "Found 2 results.\n",
      "=====================================================================\n",
      "score: 3.2676945 source: The New York Times\n",
      "body: The revival of supersonic passenger travel, thought to be long dead with the demise of Concord\n",
      "=====================================================================\n",
      "score: 2.5437517 source: The Herald-ir\n",
      "body: Charles Leclerc\n",
      "Charles Leclerc registered the maiden win of his Formula One career after romp\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source = input(\"Insert a news source: \").strip()\n",
    "terms = input(\"Insert text terms: \").strip()\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                {\"match\": {\"maintext\": terms}}, \n",
    "                {\"match\": {\"source\" : source}}\n",
    "            ]\n",
    "        }      \n",
    "    }        \n",
    "}\n",
    "query_boosted = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                {\n",
    "                    \"match\": {\n",
    "                        \"source\": {\n",
    "                            \"query\": source,\n",
    "                            \"boost\": 3\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"match\": {\n",
    "                        \"maintext\": {\n",
    "                            \"query\": terms,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "for body in [query_body, query_boosted]:\n",
    "    res = es.search(index=INDEX_NAME, body=body)\n",
    "    print (\"Found {} results.\".format(res['hits']['total']['value']))\n",
    "    for hit in res['hits']['hits']:\n",
    "        print(\"=====================================================================\")\n",
    "        print (\"score: {} source: {}\".format(hit[\"_score\"], hit[\"_source\"][\"source\"]))\n",
    "        print (\"body: {}\".format(hit[\"_source\"][\"maintext\"])[:100])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ecb09",
   "metadata": {},
   "source": [
    "# Score description: Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6325281",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = es.explain(id=\"DdTCcYUBPTSChHKmyjde\", index=INDEX_NAME, body=query_boosted)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514bff74",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Execute this code to load this set of articles and create an index. It contains 500 articles. \n",
    "The fields are:\n",
    "- *maintext*: Textual content of the article\n",
    "- *source*: News Source that wrote the article\n",
    "- *author*: Person that wrote the article\n",
    "- *date*: the date, in format yyyy-MM-dd\n",
    "\n",
    "UNIQUE SOURCES = [\"La Repubblica\", \"La Stampa\", \"Il Corriere della Sera\", \"Rai News\"]\n",
    "\n",
    "UNIQUE AUTHORS = [\"Paola Candreva\", \"Melchiorre Paccioretti\", \"Caterina De Luca\", \"Marcello Fiorentini\", \"Celestino Necci\"]\n",
    "\n",
    "The date range is 2019-12-05 -> 2020-02-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e51138d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/articles.json\", \"r\") as json_file:\n",
    "    articles = json.load(json_file)\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabafe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = index_create()\n",
    "mapping = {\n",
    "    \"properties\":{\n",
    "        \"maintext\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"english\"\n",
    "        },\n",
    "        \"source\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"whitespace\"\n",
    "        },\n",
    "        \"pub-date\": {\n",
    "            \"type\": \"date\",\n",
    "             \"format\": \"yyyy-MM-dd\"\n",
    "        },\n",
    "        \"author\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"whitespace\"\n",
    "        },\n",
    "\n",
    "    }        \n",
    "}\n",
    "es.indices.put_mapping(index=INDEX_NAME, body=mapping)\n",
    "for a in articles:\n",
    "    document = {\"maintext\": a[\"maintext\"], \"source\": a[\"source\"], \"pub-date\": a[\"date\"], \"author\": a[\"author\"]}\n",
    "    es.index(index=INDEX_NAME, body=document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ab79d3",
   "metadata": {},
   "source": [
    "# EXERCISE: TRY TO CREATE THIS QUERY\n",
    "Tell me the number of articles that were written by \"Caterina de Luca\" OR published by \"Rai News\", written in the time ranging from the 5th of December 2019 to the 25th of January 2020 (both included), and it contains the word \"world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccf0e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_body = {} #TODO insert your query here\n",
    "res = es.search(index=INDEX_NAME, body=query_body)\n",
    "print (\"Found {} results.\".format(res['hits']['total']['value']))\n",
    "for hit in res['hits']['hits']:\n",
    "    print(\"=====================================================================\")\n",
    "    print (\"score: {} source: {}, author: {}\".format(hit[\"_score\"], hit[\"_source\"][\"source\"], hit[\"_source\"][\"author\"]))\n",
    "    print (\"body: {}\".format(hit[\"_source\"][\"maintext\"])[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7dcb2",
   "metadata": {},
   "source": [
    "To the brave ones that finished early:\n",
    "**How do I do the exact same query, without the \"world\" clause, but the OR becomes a XOR?** (basically the article is either written by \"Caterina de Luca\" OR published by \"Rai News\", but those two events do not co-exist)\n",
    "So the new query to build is:\n",
    "Tell me the number of articles that were either written by \"Caterina de Luca\" OR published by \"Rai News\", and written in the time ranging from the 5th of December 2019 to the 25th of January 2020 (both included).\n",
    "\n",
    "_HINT_: similarly to \"must\", there is also a \"must_not\" construct.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "c226b66ad212a3c8eabd6b6be3829f40d39277fa7bdc3bf63a77768ea80548ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
